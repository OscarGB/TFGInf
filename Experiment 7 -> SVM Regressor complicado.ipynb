{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year_to_separate = 2010\n",
    "df = pd.read_parquet(\"time_dataset.parquet\")\n",
    "Y = df[['Municipal', 'Household', 'Recovered', 'Recicled', 'Compost', 'Disposal', 'Year']]\n",
    "X = df[[x for x in df.columns if x not in ['Country', 'COU', 'Municipal', 'Household', 'Recovered', 'Recicled', 'Compost', 'Disposal']]]\n",
    "X_train = X[X.Year < Year_to_separate]\n",
    "X_test = X[X.Year >= Year_to_separate]\n",
    "Y_train = Y[X.Year < Year_to_separate]\n",
    "Y_test = Y[X.Year >= Year_to_separate]\n",
    "#X_train = pd.read_parquet(\"Xtime/X_train.parquet\")\n",
    "#X_test = pd.read_parquet(\"Xtime/X_test.parquet\")\n",
    "#Y_train = pd.read_parquet(\"Ytime/Y_train.parquet\")\n",
    "#Y_test = pd.read_parquet(\"Ytime/Y_test.parquet\")\n",
    "X_train = X_train[['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']]\n",
    "X_test = X_test[['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX = MinMaxScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scalerX.transform(X_train))\n",
    "X_test = pd.DataFrame(scalerX.transform(X_test))\n",
    "scalerY = MinMaxScaler().fit(Y_train)\n",
    "Y_train = pd.DataFrame(scalerY.transform(Y_train))\n",
    "Y_test = pd.DataFrame(scalerY.transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_train = Y_train[[Y_train.columns[0]]]\n",
    "Y1_test = Y_test[[Y_test.columns[0]]]\n",
    "Y2_train = Y_train[[Y_train.columns[1]]]\n",
    "Y2_test = Y_test[[Y_test.columns[1]]]\n",
    "Y3_train = Y_train[[Y_train.columns[2]]]\n",
    "Y3_test = Y_test[[Y_test.columns[2]]]\n",
    "Y4_train = Y_train[[Y_train.columns[3]]]\n",
    "Y4_test = Y_test[[Y_test.columns[3]]]\n",
    "Y5_train = Y_train[[Y_train.columns[4]]]\n",
    "Y5_test = Y_test[[Y_test.columns[4]]]\n",
    "Y6_train = Y_train[[Y_train.columns[5]]]\n",
    "Y6_test = Y_test[[Y_test.columns[5]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['linear', 'rbf'],\n",
    "              'C':[0.5, 1, 5, 10, 50, 100, 500, 1000],\n",
    "              'epsilon':[0.1,0.01,0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(rf, X_train, X_test, y_train, y_test, grid, verbose=False, skip=False):\n",
    "    best_score = 0\n",
    "    par = ParameterGrid(grid)\n",
    "    ln = len(par)\n",
    "    i = 0\n",
    "    for g in par:\n",
    "        if skip and i == 46:\n",
    "            continue\n",
    "        if(verbose):\n",
    "            print(f\"Probando: {g}, {i} de {ln}\")\n",
    "        i+=1\n",
    "        rf.set_params(**g)\n",
    "        startTime = time.time()\n",
    "        rf.fit(X_train, np.ravel(y_train))\n",
    "        elapsedTime = time.time() - startTime\n",
    "        score = rf.score(X_test, y_test)\n",
    "        if(verbose):\n",
    "            print(f\"Tiempo de entrenamiento: {elapsedTime} s, score: {score}\")\n",
    "        # save if best\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_grid = g\n",
    "    print(f\"Best Score: {best_score}\")\n",
    "    print(f\"Best Parameters: {best_grid}\")\n",
    "    return best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando: {'C': 0.5, 'epsilon': 0.1, 'kernel': 'linear'}, 0 de 48\n",
      "Tiempo de entrenamiento: 0.008986711502075195 s, score: 0.935565170891488\n",
      "Probando: {'C': 0.5, 'epsilon': 0.1, 'kernel': 'rbf'}, 1 de 48\n",
      "Tiempo de entrenamiento: 0.007474184036254883 s, score: 0.8418107712192476\n",
      "Probando: {'C': 0.5, 'epsilon': 0.01, 'kernel': 'linear'}, 2 de 48\n",
      "Tiempo de entrenamiento: 0.03996539115905762 s, score: 0.999145872037926\n",
      "Probando: {'C': 0.5, 'epsilon': 0.01, 'kernel': 'rbf'}, 3 de 48\n",
      "Tiempo de entrenamiento: 0.030016660690307617 s, score: 0.9872379675487385\n",
      "Probando: {'C': 0.5, 'epsilon': 0.001, 'kernel': 'linear'}, 4 de 48\n",
      "Tiempo de entrenamiento: 0.23067331314086914 s, score: 0.9995251331937789\n",
      "Probando: {'C': 0.5, 'epsilon': 0.001, 'kernel': 'rbf'}, 5 de 48\n",
      "Tiempo de entrenamiento: 0.1279447078704834 s, score: 0.9905067976732745\n",
      "Probando: {'C': 1, 'epsilon': 0.1, 'kernel': 'linear'}, 6 de 48\n",
      "Tiempo de entrenamiento: 0.012969493865966797 s, score: 0.925619493593372\n",
      "Probando: {'C': 1, 'epsilon': 0.1, 'kernel': 'rbf'}, 7 de 48\n",
      "Tiempo de entrenamiento: 0.0093536376953125 s, score: 0.8421651213844392\n",
      "Probando: {'C': 1, 'epsilon': 0.01, 'kernel': 'linear'}, 8 de 48\n",
      "Tiempo de entrenamiento: 0.0764925479888916 s, score: 0.9991615504257997\n",
      "Probando: {'C': 1, 'epsilon': 0.01, 'kernel': 'rbf'}, 9 de 48\n",
      "Tiempo de entrenamiento: 0.029042959213256836 s, score: 0.9880886843233649\n",
      "Probando: {'C': 1, 'epsilon': 0.001, 'kernel': 'linear'}, 10 de 48\n",
      "Tiempo de entrenamiento: 0.5786557197570801 s, score: 0.9995249862686596\n",
      "Probando: {'C': 1, 'epsilon': 0.001, 'kernel': 'rbf'}, 11 de 48\n",
      "Tiempo de entrenamiento: 0.1015768051147461 s, score: 0.9907296294366309\n",
      "Probando: {'C': 5, 'epsilon': 0.1, 'kernel': 'linear'}, 12 de 48\n",
      "Tiempo de entrenamiento: 0.016308307647705078 s, score: 0.9281213964410167\n",
      "Probando: {'C': 5, 'epsilon': 0.1, 'kernel': 'rbf'}, 13 de 48\n",
      "Tiempo de entrenamiento: 0.014002799987792969 s, score: 0.8434737454725851\n",
      "Probando: {'C': 5, 'epsilon': 0.01, 'kernel': 'linear'}, 14 de 48\n",
      "Tiempo de entrenamiento: 0.10229372978210449 s, score: 0.9992148725314185\n",
      "Probando: {'C': 5, 'epsilon': 0.01, 'kernel': 'rbf'}, 15 de 48\n",
      "Tiempo de entrenamiento: 0.04954338073730469 s, score: 0.9877101865235183\n",
      "Probando: {'C': 5, 'epsilon': 0.001, 'kernel': 'linear'}, 16 de 48\n",
      "Tiempo de entrenamiento: 1.725588083267212 s, score: 0.9995244796812044\n",
      "Probando: {'C': 5, 'epsilon': 0.001, 'kernel': 'rbf'}, 17 de 48\n",
      "Tiempo de entrenamiento: 0.141434907913208 s, score: 0.9898584240348987\n",
      "Probando: {'C': 10, 'epsilon': 0.1, 'kernel': 'linear'}, 18 de 48\n",
      "Tiempo de entrenamiento: 0.021461009979248047 s, score: 0.9246391250221973\n",
      "Probando: {'C': 10, 'epsilon': 0.1, 'kernel': 'rbf'}, 19 de 48\n",
      "Tiempo de entrenamiento: 0.013489961624145508 s, score: 0.846928737895303\n",
      "Probando: {'C': 10, 'epsilon': 0.01, 'kernel': 'linear'}, 20 de 48\n",
      "Tiempo de entrenamiento: 0.3020973205566406 s, score: 0.9991866616930475\n",
      "Probando: {'C': 10, 'epsilon': 0.01, 'kernel': 'rbf'}, 21 de 48\n",
      "Tiempo de entrenamiento: 0.08841443061828613 s, score: 0.987118958083393\n",
      "Probando: {'C': 10, 'epsilon': 0.001, 'kernel': 'linear'}, 22 de 48\n",
      "Tiempo de entrenamiento: 3.750124454498291 s, score: 0.9995290845830388\n",
      "Probando: {'C': 10, 'epsilon': 0.001, 'kernel': 'rbf'}, 23 de 48\n",
      "Tiempo de entrenamiento: 0.39586782455444336 s, score: 0.9852488390780495\n",
      "Probando: {'C': 50, 'epsilon': 0.1, 'kernel': 'linear'}, 24 de 48\n",
      "Tiempo de entrenamiento: 0.021276473999023438 s, score: 0.909453149818144\n",
      "Probando: {'C': 50, 'epsilon': 0.1, 'kernel': 'rbf'}, 25 de 48\n",
      "Tiempo de entrenamiento: 0.0159914493560791 s, score: 0.874046813223989\n",
      "Probando: {'C': 50, 'epsilon': 0.01, 'kernel': 'linear'}, 26 de 48\n",
      "Tiempo de entrenamiento: 0.859067440032959 s, score: 0.9990421285536278\n",
      "Probando: {'C': 50, 'epsilon': 0.01, 'kernel': 'rbf'}, 27 de 48\n",
      "Tiempo de entrenamiento: 0.09748959541320801 s, score: 0.9887790757164605\n",
      "Probando: {'C': 50, 'epsilon': 0.001, 'kernel': 'linear'}, 28 de 48\n",
      "Tiempo de entrenamiento: 16.099724531173706 s, score: 0.9995214975552353\n",
      "Probando: {'C': 50, 'epsilon': 0.001, 'kernel': 'rbf'}, 29 de 48\n",
      "Tiempo de entrenamiento: 0.6693935394287109 s, score: 0.9878883135140549\n",
      "Probando: {'C': 100, 'epsilon': 0.1, 'kernel': 'linear'}, 30 de 48\n",
      "Tiempo de entrenamiento: 0.04170417785644531 s, score: 0.8964950318097603\n",
      "Probando: {'C': 100, 'epsilon': 0.1, 'kernel': 'rbf'}, 31 de 48\n",
      "Tiempo de entrenamiento: 0.018860816955566406 s, score: 0.8543885784824479\n",
      "Probando: {'C': 100, 'epsilon': 0.01, 'kernel': 'linear'}, 32 de 48\n",
      "Tiempo de entrenamiento: 1.4975543022155762 s, score: 0.9990431958594035\n",
      "Probando: {'C': 100, 'epsilon': 0.01, 'kernel': 'rbf'}, 33 de 48\n",
      "Tiempo de entrenamiento: 0.10210108757019043 s, score: 0.9874531411737627\n",
      "Probando: {'C': 100, 'epsilon': 0.001, 'kernel': 'linear'}, 34 de 48\n",
      "Tiempo de entrenamiento: 27.189446926116943 s, score: 0.9995260763811286\n",
      "Probando: {'C': 100, 'epsilon': 0.001, 'kernel': 'rbf'}, 35 de 48\n",
      "Tiempo de entrenamiento: 0.935455322265625 s, score: 0.9882184296146954\n",
      "Probando: {'C': 500, 'epsilon': 0.1, 'kernel': 'linear'}, 36 de 48\n",
      "Tiempo de entrenamiento: 0.08478355407714844 s, score: 0.8870272258035267\n",
      "Probando: {'C': 500, 'epsilon': 0.1, 'kernel': 'rbf'}, 37 de 48\n",
      "Tiempo de entrenamiento: 0.02265453338623047 s, score: 0.7727278666358677\n",
      "Probando: {'C': 500, 'epsilon': 0.01, 'kernel': 'linear'}, 38 de 48\n",
      "Tiempo de entrenamiento: 9.522727489471436 s, score: 0.9990730771478066\n",
      "Probando: {'C': 500, 'epsilon': 0.01, 'kernel': 'rbf'}, 39 de 48\n",
      "Tiempo de entrenamiento: 0.15463685989379883 s, score: 0.9776401249201366\n",
      "Probando: {'C': 500, 'epsilon': 0.001, 'kernel': 'linear'}, 40 de 48\n",
      "Tiempo de entrenamiento: 127.01667189598083 s, score: 0.9995174802387641\n",
      "Probando: {'C': 500, 'epsilon': 0.001, 'kernel': 'rbf'}, 41 de 48\n",
      "Tiempo de entrenamiento: 2.0698394775390625 s, score: 0.9765237635549096\n",
      "Probando: {'C': 1000, 'epsilon': 0.1, 'kernel': 'linear'}, 42 de 48\n",
      "Tiempo de entrenamiento: 0.11908888816833496 s, score: 0.8883553490359594\n",
      "Probando: {'C': 1000, 'epsilon': 0.1, 'kernel': 'rbf'}, 43 de 48\n",
      "Tiempo de entrenamiento: 0.04766726493835449 s, score: 0.7105738896590139\n",
      "Probando: {'C': 1000, 'epsilon': 0.01, 'kernel': 'linear'}, 44 de 48\n",
      "Tiempo de entrenamiento: 13.676662921905518 s, score: 0.999042781481437\n",
      "Probando: {'C': 1000, 'epsilon': 0.01, 'kernel': 'rbf'}, 45 de 48\n",
      "Tiempo de entrenamiento: 0.20188617706298828 s, score: 0.8769412488474498\n",
      "Probando: {'C': 1000, 'epsilon': 0.001, 'kernel': 'linear'}, 46 de 48\n"
     ]
    }
   ],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y1_train, Y1_test, parameters, verbose=True)\n",
    "clf1 = svm.SVR(**g).fit(X_train, np.ravel(Y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y2_train, Y2_test, parameters, verbose=True)\n",
    "clf2 = svm.SVR(**g).fit(X_train, np.ravel(Y2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y3_train, Y3_test, parameters, verbose=True)\n",
    "clf3 = svm.SVR(**g).fit(X_train, np.ravel(Y3_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y4_train, Y4_test, parameters, verbose=True, skip=True) #Saltar siempre el 46 (tarda demasiado)\n",
    "clf4 = svm.SVR(**g).fit(X_train, np.ravel(Y4_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y5_train, Y5_test, parameters, verbose=True)\n",
    "clf5 = svm.SVR(**g).fit(X_train, np.ravel(Y5_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridSearch(svm.SVR(), X_train, X_test, Y6_train, Y6_test, parameters, verbose=True)\n",
    "clf6 = svm.SVR(**g).fit(X_train, np.ravel(Y6_train))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf1 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf1.fit(X_train, np.ravel(Y1_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf1.score(X_test, Y1_test))\n",
    "print(clf1.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf2 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf2.fit(X_train, np.ravel(Y2_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf2.score(X_test, Y2_test))\n",
    "print(clf2.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf3 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf3.fit(X_train, np.ravel(Y3_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf3.score(X_test, Y3_test))\n",
    "print(clf3.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf4 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf4.fit(X_train, np.ravel(Y4_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf4.score(X_test, Y4_test))\n",
    "print(clf4.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf5 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf5.fit(X_train, np.ravel(Y5_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf5.score(X_test, Y5_test))\n",
    "print(clf5.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf6 = GridSearchCV(svm.SVR(), parameters, n_jobs=-1)\n",
    "startTime = time.time()\n",
    "clf6.fit(X_train, np.ravel(Y6_train))\n",
    "elapsedTime = time.time() - startTime\n",
    "print('{} s'.format(int(elapsedTime)))\n",
    "print(clf6.score(X_test, Y6_test))\n",
    "print(clf6.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(clf1.predict(X_test.iloc[0::4]) - np.array(Y1_test.iloc[0::4][0])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(clf1.predict(X_test.iloc[1::4]) - np.array(Y1_test.iloc[1::4][0])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(clf1.predict(X_test.iloc[2::4]) - np.array(Y1_test.iloc[2::4][0])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(clf1.predict(X_test.iloc[3::4]) - np.array(Y1_test.iloc[3::4][0])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One concrete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 120\n",
    "scalerY.inverse_transform([[clf1.predict([X_test.iloc[i]])[0], clf2.predict([X_test.iloc[i]])[0], clf3.predict([X_test.iloc[i]])[0], \n",
    "                          clf4.predict([X_test.iloc[i]])[0], clf5.predict([X_test.iloc[i]])[0], clf6.predict([X_test.iloc[i]])[0], 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerY.inverse_transform([Y_test.iloc[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos con España"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'ESP'\n",
    "esp = Complete[Complete.COU == country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Municipal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Municipal)\n",
    "predictions = clf1.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[0] for a in scalerY.inverse_transform([[a,0,0,0,0,0,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura municipal en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Household)\n",
    "predictions = clf2.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[1] for a in scalerY.inverse_transform([[0,a,0,0,0,0,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura doméstica en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Recovered)\n",
    "predictions = clf3.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[2] for a in scalerY.inverse_transform([[0,0,a,0,0,0,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura recuperada en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recicled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Recicled)\n",
    "predictions = clf4.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[3] for a in scalerY.inverse_transform([[0,0,0,a,0,0,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura reciclada en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Compost)\n",
    "predictions = clf5.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[4] for a in scalerY.inverse_transform([[0,0,0,0,a,0,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura compostada en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(esp.Year)\n",
    "mun = list(esp.Disposal)\n",
    "predictions = clf1.predict(pd.DataFrame(scalerX.transform(Complete.loc[esp.index[-4:],:][['Built', 'Below Secundary', 'Income Median',\n",
    "       'Population', 'Over 65', 'Over 65 Percentage', 'Over 85',\n",
    "       'Over 85 Percentage', 'Over 50', 'Over 50 Percentage', 'Under 20',\n",
    "       'Under 20 Percentage', 'Income Per Capita', 'Tourism', 'Area',\n",
    "       'Built Area', 'Last Year Municipal', 'Last Year Household',\n",
    "       'Last Year Recovered', 'Last Year Recicled', 'Last Year Compost',\n",
    "       'Last Year Disposal',\n",
    "       'Last Year Built', 'Difference Built',\n",
    "       'Last Year Below Secundary', 'Difference Below Secundary',\n",
    "       'Last Year Population', 'Difference Population', 'Last Year Tourism',\n",
    "       'Difference Tourism']])))\n",
    "predictions = [a[5] for a in scalerY.inverse_transform([[0,0,0,0,0,a,0] for a in predictions])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(years, mun, lw=2, label='real')\n",
    "plt.axvline(x=2013.5, c='green', lw=1, ls=':', label='separación')\n",
    "plt.plot(years[-4:], predictions, c='red', lw=2, label='predecido')\n",
    "plt.title(\"Basura deshechada en España\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Miles de toneladas\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
